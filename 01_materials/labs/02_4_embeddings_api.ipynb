{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ef0627",
   "metadata": {},
   "source": [
    "# Embeddings via API\n",
    "\n",
    "In this notebook, we demonstrate how to obtain embeddings using OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d340a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6890865",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    # Freedom\n",
    "    \"Freedom consists not in doing what we like, but in having the right to do what we ought.\",\n",
    "    \"Those who deny freedom to others deserve it not for themselves.\",\n",
    "    \"Liberty, when it begins to take root, is a plant of rapid growth.\",\n",
    "    \"Freedom lies in being bold.\",\n",
    "    \"Is freedom anything else than the right to live as we wish?\",\n",
    "    \"I am no bird and no net ensnares me: I am a free human being with an independent will.\",\n",
    "    \"The secret to happiness is freedom... And the secret to freedom is courage.\"\n",
    "    \"Freedom is the oxygen of the soul.\", \n",
    "    \"Life without liberty is like a body without spirit.\"\n",
    "    # Friendship\n",
    "    \"There is nothing on this earth more to be prized than true friendship.\",\n",
    "    \"There are no strangers here; Only friends you havenâ€™t yet met.\",\n",
    "    \"Friendship is the only cement that will ever hold the world together.\",\n",
    "    \"A true friend is someone who is there for you when he'd rather be anywhere else.\",\n",
    "    \"Friendship is the golden thread that ties the heart of all the world.\", \n",
    "    \"Your friend is the man who knows all about you and still likes you.\",\n",
    "    \"A single rose can be my garden... a single friend, my world.\"\n",
    "    # Food\n",
    "    \"One cannot think well, love well, sleep well, if one has not dined well.\",\n",
    "    \"Let food be thy medicine and medicine be thy food.\",\n",
    "    \"People who love to eat are always the best people.\",\n",
    "    \"The only way to get rid of a temptation is to yield to it.\",\n",
    "    \"Food is our common ground, a universal experience.\",\n",
    "    \"Life is uncertain. Eat dessert first.\",\n",
    "    \"All you need is love. But a little chocolate now and then doesn't hurt.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a07d1",
   "metadata": {},
   "source": [
    "OpenAI's text embeddings are available through the embeddings API. A key reference is the [Embeddings API documentation](https://platform.openai.com/docs/guides/embeddings).\n",
    "\n",
    "There are three models that we can choose from, depending on [the size of the hidden representation, latency, and cost](https://platform.openai.com/docs/guides/embeddings#embedding-models):\n",
    "\n",
    "+ `text-embedding-3-small`\n",
    "+ `text-embedding-3-large`\n",
    "+ `text-embedding-ada-002`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd77ae",
   "metadata": {},
   "source": [
    "A simple implementation would call the embeddings API for each phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "embeddings = [get_embedding(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_array = np.array(embeddings)\n",
    "embeddings_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a6038",
   "metadata": {},
   "source": [
    "## A Note on Similarity\n",
    "\n",
    "One important characteristic of embeddings is that they can be used to measure the relatedness of text strings. To see this, we can plot a reduced forms of the embeddings using Principal Components Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2fa30",
   "metadata": {},
   "source": [
    "Similarity between two texts can be understood in two ways:\n",
    "\n",
    "+ Lexical similarity refers to similarity of the choice of words. For example, \"cats are fun\" and \"cats are furry\" are similar in that they have two words in common.\n",
    "+ Semantical similarity refers to similarity in the words meaning. For example, \"the bottle is empty\" and \"there is nothing in the bottle\" are similar in meaning, but the phrases do not have many words in common.\n",
    "\n",
    "Using count or tf-idf tokenization, we can calculate lexical similarity; using embeddings, we can compute (model-dependent) lexical similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775395af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"]).assign(label = documents)\n",
    "\n",
    "# Create the scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x='x', y='y', data=df, ax=ax)\n",
    "\n",
    "# Add labels\n",
    "texts = []\n",
    "for i, row in df.iterrows():\n",
    "    texts.append(ax.text(row['x'], row['y'], row['label'], fontsize=6))\n",
    "\n",
    "# Adjust text positions to avoid overlap\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='black', lw=0.5))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
